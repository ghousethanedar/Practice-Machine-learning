{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tita1=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tita1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tita1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tita1[['Pclass','Survived','SibSp','Parch']]=tita1[['Pclass','Survived','SibSp','Parch']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tita1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null object\n",
      "Pclass         891 non-null object\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null object\n",
      "Parch          891 non-null object\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(1), object(9)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "tita1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tita=tita1.drop(['Cabin','Name','Embarked','Ticket'],axis=1)\n",
    "tita.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tita1['PassengerId'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tita.Sex=tita.Sex.replace({'male':1,'female':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_Parch_0 = resample(tita[tita['Parch']=='0'],n_samples=500,replace=True,random_state=1)\n",
    "df_Parch_1 = resample(tita[tita['Parch']=='1'],n_samples=500,replace=True,random_state=1)\n",
    "\n",
    "df_Parch_2 = resample(tita[tita['Parch']=='2'],n_samples=500,replace=True,random_state=1)\n",
    "\n",
    "df_Parch_3 = resample(tita[tita['Parch']=='3'],n_samples=500,replace=True,random_state=1)\n",
    "\n",
    "df_Parch_4 = resample(tita[tita['Parch']=='4'],n_samples=500,replace=True,random_state=1)\n",
    "\n",
    "df_Parch_5 = resample(tita[tita['Parch']=='5'],n_samples=500,replace=True,random_state=1)\n",
    "df_Parch_6 = resample(tita[tita['Parch']=='6'],n_samples=500,replace=True,random_state=1)\n",
    "#df_survived_1=resample(tita[tita['Survived']=='1'],n_samples=500,replace=True,random_state=1)\n",
    "#df_survived_1=resample(tita[tita['Survived']=='0'],n_samples=500,replace=True,random_state=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tita=pd.concat([df_Parch_0,df_Parch_1,df_Parch_2,df_Parch_3,df_Parch_4,df_Parch_5,df_Parch_6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "first,second=train_test_split(tita,test_size=0.3,random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=StandardScaler()\n",
    "ss.fit(first[['Age','Fare']])\n",
    "first[['Age','Fare']]=ss.transform(first[['Age','Fare']])\n",
    "second[['Age','Fare']]=ss.transform(second[['Age','Fare']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "first=pd.get_dummies(first)\n",
    "second=pd.get_dummies(second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-3d8348ffe097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Fare'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pca'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Fare'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#pca.fit(second[['Age','Fare']])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \"\"\"\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[0;32m--> 381\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "first[['Age','Fare']]=first[['Age','Fare']]-first[['Age','Fare']].mean(axis=0)\n",
    "second[['Age','Fare']]=second[['Age','Fare']]-second[['Age','Fare']].mean(axis=0)\n",
    "\n",
    "\n",
    "pca=PCA(n_components=1)\n",
    "pca.fit(first[['Age','Fare']])\n",
    "first['pca']=pca.transform(first[['Age','Fare']])\n",
    "#pca.fit(second[['Age','Fare']])\n",
    "second['pca']=pca.transform(second[['Age','Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of first and second (2450, 17) (1050, 17)\n"
     ]
    }
   ],
   "source": [
    "first=first.drop(['Survived_0','SibSp_0','SibSp_5','Parch_0','Age','Fare'],axis=1)\n",
    "second=second.drop(['Survived_0','SibSp_0','SibSp_5','Parch_0','Age','Fare'],axis=1)\n",
    "print('shape of first and second',first.shape,second.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=first.drop('Survived_1',axis=1)\n",
    "y=first['Survived_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain1,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,random_state=22,stratify=y)\n",
    "xtrain=xtrain1\n",
    "xtrain=xtrain.drop('PassengerId',axis=1)\n",
    "xtest=xtest.drop('PassengerId',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|       Model name       |   Accuracy_score   |  Precision_score   |    Recall_score    |      F1_score      |\n",
      "+------------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   LogisticRegression   | 0.8884353741496599 | 0.8876376901221622 | 0.8884353741496599 | 0.886297360733451  |\n",
      "|          KNN           | 0.9401360544217687 | 0.9398714152327597 | 0.9401360544217687 | 0.9397149335924846 |\n",
      "| DecisionTreeClassifier | 0.9061224489795918 | 0.9097670870440828 | 0.9061224489795918 | 0.9029116412115085 |\n",
      "| RandomForestClassifier | 0.9823129251700681 | 0.9823365160953718 | 0.9823129251700681 | 0.9823226551662718 |\n",
      "+------------------------+--------------------+--------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "## code to find the best model for the dataset\n",
    "\n",
    "## Before using this template you should find the hyperparameters for the KNN \n",
    "## and Decision and random Forest the add those parameters in the model below \n",
    "\n",
    "## After selecting the best model we can use KFold CV to check for the bias error and variance error\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from prettytable import PrettyTable\n",
    "from sklearn import metrics\n",
    "\n",
    "report= PrettyTable()\n",
    "report.field_names=['Model name','Accuracy_score','Precision_score','Recall_score','F1_score']\n",
    "\n",
    "\n",
    "regressor=['LogisticRegression','KNN','DecisionTreeClassifier','RandomForestClassifier']\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1_score=[]\n",
    "\n",
    "for regressor in regressor:\n",
    "    if regressor=='LogisticRegression':\n",
    "        model1=LogisticRegression()\n",
    "        model1.fit(xtrain,ytrain)\n",
    "        log_pred=pd.DataFrame(model1.predict(xtest))\n",
    "        #Evaluation metrics\n",
    "        report.add_row([regressor,\n",
    "                    metrics.accuracy_score(ytest,log_pred),\n",
    "                    metrics.precision_score(ytest,log_pred,average='weighted'),\n",
    "                    metrics.recall_score(ytest,log_pred,average='weighted'),\n",
    "                    metrics.f1_score(ytest,log_pred,average='weighted')])\n",
    "        \n",
    "    elif regressor=='KNN': \n",
    "        model2=KNeighborsClassifier(n_neighbors=4,p=35)\n",
    "        model2.fit(xtrain,ytrain)\n",
    "        knn_pred=model2.predict(xtest)\n",
    "        #Evaluation metrics\n",
    "        report.add_row([regressor,\n",
    "                    metrics.accuracy_score(ytest,knn_pred),\n",
    "                    metrics.precision_score(ytest,knn_pred,average='weighted'),\n",
    "                    metrics.recall_score(ytest,knn_pred,average='weighted'),\n",
    "                    metrics.f1_score(ytest,knn_pred,average='weighted')])\n",
    "    elif regressor=='DecisionTreeClassifier':\n",
    "        model3=DecisionTreeClassifier(min_samples_leaf=6,max_leaf_nodes=8,max_depth=8,criterion='entropy')\n",
    "        model3.fit(xtrain,ytrain)\n",
    "        dec_pred=model3.predict(xtest)\n",
    "        #Evaluation metrics\n",
    "        report.add_row([regressor,\n",
    "                    metrics.accuracy_score(ytest,dec_pred),\n",
    "                    metrics.precision_score(ytest,dec_pred,average='weighted'),\n",
    "                    metrics.recall_score(ytest,dec_pred,average='weighted'),\n",
    "                    metrics.f1_score(ytest,dec_pred,average='weighted')])\n",
    "        \n",
    "    elif regressor=='RandomForestClassifier':\n",
    "        model4=RandomForestClassifier(criterion='entropy',n_estimators=45,max_features=8)\n",
    "        model4.fit(xtrain,ytrain)\n",
    "        random_pred=model4.predict(xtest)\n",
    "        #Evaluation metrics\n",
    "        report.add_row([regressor,\n",
    "                    metrics.accuracy_score(ytest,random_pred),\n",
    "                    metrics.precision_score(ytest,random_pred,average='weighted'),\n",
    "                    metrics.recall_score(ytest,random_pred,average='weighted'),\n",
    "                    metrics.f1_score(ytest,random_pred,average='weighted')])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to find the best hyper parameters for the KNN and DecisionTree and Random forest\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "## code to find the best model for the dataset\n",
    "\n",
    "\n",
    "best_par= PrettyTable()\n",
    "best_par.field_names=['Model name','Best Parameters','Best Score']\n",
    "\n",
    "\n",
    "regressor=['KNN','DecisionTreeClassifier','RandomForestClassifier']\n",
    "\n",
    "\n",
    "for regressor in regressor:\n",
    "    if regressor=='KNN': \n",
    "        grid1={'n_neighbors': np.arange(1,50),'p': np.arange(1,50)}\n",
    "        ran_search1=RandomizedSearchCV(model2,grid1,cv=3)\n",
    "        ran_search1.fit(xtrain,ytrain)\n",
    "        best_par.add_row([regressor,\n",
    "                          ran_search1.best_params_,\n",
    "                          ran_search1.best_score_])\n",
    "    elif regressor=='DecisionTreeClassifier':\n",
    "        \n",
    "        \n",
    "        grid2={'criterion':['gini','entropy'],'max_depth': np.arange(2,10),'max_leaf_nodes':np.arange(2,10),'min_samples_leaf':np.arange(2,10)}\n",
    "        ran_search2=RandomizedSearchCV(model3,grid2,cv=3)\n",
    "        ran_search2.fit(xtrain,ytrain)\n",
    "        best_par.add_row([regressor,\n",
    "                          ran_search2.best_params_,\n",
    "                          ran_search2.best_score_])\n",
    "        \n",
    "    elif regressor=='RandomForestClassifier':\n",
    "        \n",
    "        \n",
    "        grid3={'criterion':['gini','entropy'],'n_estimators':np.arange(1,100),'max_features':np.arange(1,10)}\n",
    "        ran_search3=RandomizedSearchCV(model4,grid3,cv=3)\n",
    "        ran_search3.fit(xtrain,ytrain)\n",
    "        best_par.add_row([regressor,\n",
    "                          ran_search3.best_params_,\n",
    "                          ran_search3.best_score_])\n",
    "        \n",
    "print(best_par)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From the above details we can tell Random forest classifier is performing well in this dataset with the parameters as 'n_estimators': 15, 'max_features': 7, 'criterion': 'gini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the random forest classifier using the KFold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf=KFold(n_splits=10)\n",
    "random_final=PrettyTable()\n",
    "random_final.field_names=['Model','Accuracy','Precision','Recall','F1_score']\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1_score=[]\n",
    "for train,test in kf.split(xtrain,ytrain):\n",
    "    \n",
    "    xtrain1,xtest1=xtrain.iloc[train,:],xtrain.iloc[test,:]\n",
    "    ytrain1=ytrain.iloc[train]\n",
    "    ytest1=ytrain.iloc[test]\n",
    "    \n",
    "    model4=RandomForestClassifier(n_estimators=45,max_features=,criterion='entropy')\n",
    "    model4.fit(xtrain1,ytrain1)\n",
    "    random_pred=model4.predict(xtest1)\n",
    "    #Evaluation metrics\n",
    "    accuracy.append(metrics.accuracy_score(ytest1,random_pred))\n",
    "    precision.append(metrics.precision_score(ytest1,random_pred,average='weighted'))\n",
    "    recall.append(metrics.recall_score(ytest1,random_pred,average='weighted'))\n",
    "    f1_score.append(metrics.f1_score(ytest1,random_pred,average='weighted'))\n",
    "random_final.add_row([regressor,np.mean(accuracy),np.mean(precision),np.mean(recall),np.mean(f1_score)])\n",
    "                        \n",
    "\n",
    "\n",
    "print(random_final)\n",
    "\n",
    "metrics.confusion_matrix(ytest1,random_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sec=first.drop('Survived_1',axis=1)\n",
    "y_sec=first['Survived_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf=KFold(n_splits=10)\n",
    "random_final=PrettyTable()\n",
    "random_final.field_names=['Model','Accuracy','Precision','Recall','F1_score']\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1_score=[]\n",
    "for train,test in kf.split(x_sec,y_sec):\n",
    "    \n",
    "    xtrain1,xtest1=x_sec.iloc[train,:],x_sec.iloc[test,:]\n",
    "    ytrain1=y_sec.iloc[train]\n",
    "    ytest1=y_sec.iloc[test]\n",
    "    \n",
    "    model4=RandomForestClassifier(n_estimators=63,max_features=7,criterion='entropy')\n",
    "    model4.fit(xtrain1,ytrain1)\n",
    "    random_pred=model4.predict(xtest1)\n",
    "    #Evaluation metrics\n",
    "    accuracy.append(metrics.accuracy_score(ytest1,random_pred))\n",
    "    precision.append(metrics.precision_score(ytest1,random_pred,average='weighted'))\n",
    "    recall.append(metrics.recall_score(ytest1,random_pred,average='weighted'))\n",
    "    f1_score.append(metrics.f1_score(ytest1,random_pred,average='weighted'))\n",
    "random_final.add_row([regressor,np.mean(accuracy),np.mean(precision),np.mean(recall),np.mean(f1_score)])\n",
    "                        \n",
    "\n",
    "\n",
    "print(random_final)\n",
    "\n",
    "metrics.confusion_matrix(ytest1,random_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tita=pd.read_csv('test.csv')\n",
    "test_tita.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tita1=test_tita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tita.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tita.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tita['Age']=test_tita['Age'].fillna(test_tita['Age'].median())\n",
    "test_tita['Fare']=test_tita['Fare'].fillna(test_tita['Fare'].median())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=StandardScaler()\n",
    "ss.fit(test_tita[['Age','Fare']])\n",
    "test_tita[['Age','Fare']]=ss.transform(test_tita[['Age','Fare']])\n",
    "#second[['Age','Fare']]=ss.transform(second[['Age','Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tita[['Pclass','SibSp','Parch']]=test_tita[['Pclass','SibSp','Parch']].astype('str')\n",
    "\n",
    "test_tita.shape\n",
    "\n",
    "test_tita.info()\n",
    "\n",
    "test_tita=test_tita.drop(['Cabin','Name','Embarked','PassengerId','Ticket'],axis=1)\n",
    "test_tita=test_tita.dropna()\n",
    "test_tita.shape\n",
    "\n",
    "test_tita.Sex=test_tita.Sex.replace({'male':1,'female':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tita=pd.get_dummies(test_tita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tita.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tita.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "test_tita[['Age','Fare']]=test_tita[['Age','Fare']]-test_tita[['Age','Fare']].mean(axis=0)\n",
    "\n",
    "pca=PCA(n_components=1)\n",
    "pca.fit(test_tita[['Age','Fare']])\n",
    "test_tita['pca']=pca.transform(test_tita[['Age','Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tita=test_tita.drop(['SibSp_0','SibSp_5','Parch_0','SibSp_8','Parch_9','Age','Fare'],axis=1)\n",
    "\n",
    "test_tita.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final1=pd.DataFrame(model1.predict(test_tita),columns=['Survived'])\n",
    "final2=pd.DataFrame(model2.predict(test_tita),columns=['Survived'])\n",
    "\n",
    "final3=pd.DataFrame(model3.predict(test_tita),columns=['Survived'])\n",
    "\n",
    "final4=pd.DataFrame(model4.predict(test_tita),columns=['Survived'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final1['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final2['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final3['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final4['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission=pd.concat([test_tita1['PassengerId'],final3],axis=1)\n",
    "#submission.to_csv('titanic_sub6.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-error-mean  train-error-std  test-error-mean  test-error-std\n",
      "0          0.168513         0.005183         0.168513        0.020730\n",
      "1          0.168513         0.005183         0.168513        0.020730\n",
      "2          0.162974         0.014130         0.167347        0.019825\n",
      "3          0.155248         0.010318         0.157435        0.026011\n",
      "4          0.133965         0.022702         0.147522        0.027634\n"
     ]
    }
   ],
   "source": [
    "# XG Boost\n",
    "import xgboost as xgb\n",
    "\n",
    "xg = xgb.XGBClassifier(max_depth=2, learning_rate=0.01) # 0.78947\n",
    "\n",
    "# Fitting the Model\n",
    "labels_xgb = xg.fit(xtrain,ytrain).predict(xtest)\n",
    "\n",
    "# Prepare the Data for Submission\n",
    "#submission=pd.concat([xtrain['PassengerId'],final3],axis=1)\n",
    "#submission.to_csv('xgboost.csv',index=False)\n",
    "\n",
    "# Exporting the Dataset as CSV File\n",
    "#solution.to_csv(\"XGBoost Model.csv\", index = False)\n",
    "\n",
    "# Apply Cross Validation on XGB\n",
    "titanic_dmat = xgb.DMatrix(data = xtrain, label=ytrain)\n",
    "\n",
    "# Parameters\n",
    "params = {\"objective\":\"binary:logistic\", \"max_depth\":2}\n",
    "\n",
    "# Apply Cross Validation using XGB\n",
    "cv_results = xgb.cv(params=params, dtrain=titanic_dmat, \n",
    "       num_boost_round=5, nfold = 5, metrics=\"error\", as_pandas=True)\n",
    "\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array length 735 does not match index length 891",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8683adc80f06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Prepare the Data for Submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m solution = pd.DataFrame({\"PassengerId\":tita1[\"PassengerId\"], \n\u001b[0;32m---> 12\u001b[0;31m                          \"Survived\":labels_vc})\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Exporting the Dataset as CSV File\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   7354\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7356\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7358\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   7410\u001b[0m                     msg = ('array length %d does not match index length %d' %\n\u001b[1;32m   7411\u001b[0m                            (lengths[0], len(index)))\n\u001b[0;32m-> 7412\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7413\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7414\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array length 735 does not match index length 891"
     ]
    }
   ],
   "source": [
    "# Voting Classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "vc = VotingClassifier(estimators=[('Log',model1),('Knn',model2),('DTREE', model3),\n",
    "                                  (\"RF\", model4)], \n",
    "                      voting=\"soft\")\n",
    "\n",
    "# Fitting the Model\n",
    "labels_vc = vc.fit(xtrain,ytrain).predict(xtest)\n",
    "\n",
    "# Prepare the Data for Submission\n",
    "solution = pd.DataFrame({\"PassengerId\":tita1[\"PassengerId\"], \n",
    "                         \"Survived\":labels_vc})\n",
    "\n",
    "# Exporting the Dataset as CSV File\n",
    "solution.to_csv(\"Voting Classifier Model.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tita.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
